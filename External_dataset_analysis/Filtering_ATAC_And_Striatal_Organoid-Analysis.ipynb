{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1197b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import re\n",
    "from scipy.stats.stats import pearsonr\n",
    "#import rpy2.robjects as robjects\n",
    "import random\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import copy\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.stats import binom_test\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "\n",
    "#Try to figure out what the characteristics are of promoters that have matching directionality!\n",
    "#But first, we need to filter the peaks!\n",
    "#Lets just filter so that they have to have matching direction in replicates and humreffed/chpreffed if they are to be called\n",
    "#as significant\n",
    "def match_dir(a, b, cutoff_sig = 0.5):\n",
    "    if abs(a) > cutoff_sig or abs(b) > cutoff_sig:\n",
    "        if a >= 0 and b >= 0 or a <= 0 and b <= 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def bias_check(a, b):\n",
    "    if abs(a-b) > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def map_bias_check(a, b):\n",
    "    if abs(np.log2(a/b)) > 2:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def mean_rat(file, v):\n",
    "    if \"SKM\" not in file and \"HP\" not in file:\n",
    "        v[\"Mean Ratio\"] = np.log2(((v[4] + v[6])/(v[5] + v[7]) + (v[9] + v[11])/(v[10] + v[12]))/2)\n",
    "    else:\n",
    "        v[\"Mean Ratio\"] = np.log2(((v[4]/v[5]) + (v[7]/v[8]))/2)\n",
    "    return v\n",
    "\n",
    "#Identify cell type specific peaks\n",
    "def unique_ct(ct, l, name):\n",
    "    if ct in name:\n",
    "        for i in l:\n",
    "            if i in name:\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def ubiq(l, name, cut):\n",
    "    c = 0\n",
    "    for i in l:\n",
    "        if i in name:\n",
    "            c += 1\n",
    "    if c >= cut:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#Read in the files, can adjust conditions in first if statement to determine which are most important.\n",
    "def readin(cell, reffed, folder):\n",
    "    files = os.listdir(folder)\n",
    "    cols = [\"Peak\"]\n",
    "    d = {}\n",
    "    for f in files:\n",
    "        if cell in f and reffed in f and \".txt\" in f:\n",
    "            cols.append(f)\n",
    "            v = pd.read_csv(folder+ \"/\" + f, sep = \"\\t\", header = None)\n",
    "            for index, row in v.iterrows():\n",
    "                if \"eak\" in row[0]:\n",
    "                    if row[0] in d.keys():\n",
    "                        d[row[0]].append(row[1])\n",
    "                    else:\n",
    "                        d[row[0]] = [row[1]]\n",
    "    to_df = []\n",
    "    for key in d.keys():\n",
    "        to_df.append([key] + d[key])\n",
    "    df = pd.DataFrame(to_df)\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "#vv = pd.read_csv(\"MN\" + \"_ATAC_Filtered_SNP_Init.txt\", sep = '\\t')\n",
    "def addgene(v, t):\n",
    "    o = []\n",
    "    for index, row in v.iterrows():\n",
    "        l = row[\"Peak Chpreffed\"]\n",
    "        try:\n",
    "            if t == \"CM\": \n",
    "                if \"hancer\" in l:\n",
    "                    gene = l.split(\"_\")[7]\n",
    "                    o.append(list(row) + [gene])\n",
    "                else:\n",
    "                    gene = l.split(\"_\")[7]\n",
    "                    o.append(list(row) + [gene])\n",
    "            else:\n",
    "                if \"hancer\" in l:\n",
    "                    gene = l.split(\"_\")[6]\n",
    "                    o.append(list(row) + [gene])\n",
    "                else:\n",
    "                    gene = l.split(\"_\")[6]\n",
    "                    o.append(list(row) + [gene])\n",
    "        except:\n",
    "            pass\n",
    "    df = pd.DataFrame(o)\n",
    "    df.columns = list(v.columns) + [\"gene\"]\n",
    "    return df\n",
    "#vvv = addgene(vv, \"MN\")\n",
    "\n",
    "def txt_to_bed(txt):\n",
    "    v = pd.read_csv(txt, sep = \"\\t\")\n",
    "    out = []\n",
    "    for index, row in v.iterrows():\n",
    "        g = row[\"Genomic location\"]\n",
    "        l = [g.split(\":\")[0], g.split(\":\")[1].split(\"-\")[0], g.split(\":\")[1].split(\"-\")[1]] + list(row)\n",
    "        out.append(l)\n",
    "    df = pd.DataFrame(out)\n",
    "    df.to_csv(txt.replace(\".txt\", \".bed\"), sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3078c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amalgamate the counts for uploading to GSE\n",
    "df = 0\n",
    "ind = 1\n",
    "x = 'ATAC7_CM_Hyb1_total'\n",
    "d = {\"Chimp\":\"chimp\", \"Human\":\"human\", \"BothAlleles\":\"total\"}\n",
    "for file in os.listdir('All_Peaks'):\n",
    "    if \"humreffed_all_peaks.txt\" in file:\n",
    "        v = pd.read_csv(\"All_Peaks/\" + file, sep = '\\t', header = None).set_index(0)\n",
    "        spec = d[file.split(\"_\")[3]]\n",
    "        start_string = \"_\".join(file.split(\"_\")[0:3])\n",
    "        v.columns = [start_string + \"_\" + spec]\n",
    "        #print(v.columns)\n",
    "        if ind:\n",
    "            df = v\n",
    "            ind = 0\n",
    "        else:\n",
    "            df = df.join(v)\n",
    "#df.to_csv(\"ATAC_Counts_Table_Human_Aligned.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f36395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the striatal organoid data for plotting\n",
    "v = pd.read_csv(\"GSE132403_Data_03_all_peak_counts_updated.tsv\", sep = \"\\t\").set_index(\"Peak\").T\n",
    "out = []\n",
    "def cpm(x):\n",
    "    s = sum(list(x))\n",
    "    x = [i*1000000/s for i in list(x)]\n",
    "    return x\n",
    "\n",
    "for index, row in v.iterrows():\n",
    "    out.append(cpm(row))\n",
    "v_cpm = pd.DataFrame(out).T\n",
    "\n",
    "v_cpm.index = v.T.index\n",
    "v_cpm.columns = v.T.columns\n",
    "\n",
    "v_cpmf = pd.DataFrame(v_cpm.loc[\"peak_12384\"])\n",
    "out = []\n",
    "for index, row in v_cpmf.iterrows():\n",
    "    out.append([row[\"peak_12384\"], index.split(\"_\")[1], \"D\" + index.split(\"_\")[2], index.split(\"_\")[4], index.split(\"_\")[3]])\n",
    "df = pd.DataFrame(out)\n",
    "df.columns = [\"CPM\", \"Cell Type\", \"Day\", \"Organoid\", \"Line\"]\n",
    "\n",
    "df.to_csv(\"GAD1_HAR_Containing_Peak_ATAC_CPM.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform peak filtering and compute binomil p-values when we have replicates\n",
    "#Ignore the \"interpeak\" parts as these were unused\n",
    "fix_all_peaks = {\"peak__peakMN86472387\":\"peak_MN_64043\", \"peak_HP_MN_PP_SKM4.96014\":\"peak_HP_MN_PP_SKM_78155\", \"peak_HP_MN_PP_SKM4.944030000000001\":\"peak_HP_MN_PP_SKM_77849\", \"peak_HP_MN_PP_SKM4.83314\":\"peak_HP_MN_PP_SKM_268883\", \"peak_HP_MN_PP_SKM4.73749\":\"peak_HP_MN_PP_SKM_179978\"}\n",
    "fix_all_peaks_down = {\"peak_HP_MN_PP_SKM25.1425\":\"peak_HP_MN_PP_35800\", \"peak_HP_MN_PP_SKM36.5991\":\"peak_HP_MN_PP_SKM_68285\"}\n",
    "\n",
    "def filter_rep(ct=\"CM\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC7\", \"S2\":\"ATAC8\"}, suffix = \"_all_peaks.txt\"):\n",
    "    df_hum = readin(ct, \"umreffed\", fold)\n",
    "    df_chp = readin(ct, \"hpreffed\", fold)\n",
    "    if fold == \"All_Peaks\" or fold == \"Down\":\n",
    "        indices = []\n",
    "        for index, row in df_hum.iterrows():\n",
    "            if \"promoter\" in row[\"Peak\"]:\n",
    "                ad = row[\"Peak\"].split(\"promoter\")[0][:-1]\n",
    "            else:\n",
    "                ad = row[\"Peak\"].split(\"enhancer\")[0][:-1]\n",
    "            indices.append(ad)\n",
    "        df_hum.index = indices\n",
    "\n",
    "        indices = []\n",
    "        for index, row in df_chp.iterrows():\n",
    "            if \"promoter\" in row[\"Peak\"]:\n",
    "                ad = row[\"Peak\"].split(\"promoter\")[0][:-1]\n",
    "            else:\n",
    "                ad = row[\"Peak\"].split(\"enhancer\")[0][:-1]\n",
    "            indices.append(ad)\n",
    "        df_chp.index = indices\n",
    "\n",
    "        c = list(df_hum.columns)\n",
    "        c[0] = \"Peak Humreffed\"\n",
    "        df_hum.columns = c\n",
    "        c = list(df_chp.columns)\n",
    "        c[0] = \"Peak Chpreffed\"\n",
    "        df_chp.columns = c\n",
    "        df = df_hum.join(df_chp)\n",
    "    else:\n",
    "        df_hum  = df_hum.set_index(\"Peak\")\n",
    "        df_chp = df_chp.set_index(\"Peak\")\n",
    "        df = df_hum.join(df_chp)\n",
    "        df[\"Peak\"] = df.index\n",
    "    df[mapping[\"S1\"] + \"_Human_Humr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix])\n",
    "    df[mapping[\"S1\"] + \"_Chimp_Humr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix])\n",
    "    df[mapping[\"S2\"] + \"_Human_Humr_CPM\"] = 1000000*(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_humreffed\" + suffix]+1)/np.sum(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_humreffed\" + suffix])\n",
    "    df[mapping[\"S2\"] + \"_Chimp_Humr_CPM\"] = 1000000*(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_humreffed\" + suffix]+1)/np.sum(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_humreffed\" + suffix])\n",
    "    df[mapping[\"S1\"] + \"_Human_Chpr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix])\n",
    "    df[mapping[\"S1\"] + \"_Chimp_Chpr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix])\n",
    "    df[mapping[\"S2\"] + \"_Human_Chpr_CPM\"] = 1000000*(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_chpreffed\" + suffix]+1)/np.sum(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_chpreffed\" + suffix])\n",
    "    df[mapping[\"S2\"] + \"_Chimp_Chpr_CPM\"] = 1000000*(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_chpreffed\" + suffix]+1)/np.sum(df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_chpreffed\" + suffix])\n",
    "\n",
    "    df[\"Total_Counts_Humr\"] = df[mapping[\"S1\"] + \"_Human_Humr_CPM\"] + df[mapping[\"S1\"] + \"_Chimp_Humr_CPM\"] + df[mapping[\"S2\"] + \"_Human_Humr_CPM\"] + df[mapping[\"S2\"] + \"_Chimp_Humr_CPM\"]\n",
    "    df[\"Total_Counts_Chpr\"] = df[mapping[\"S1\"] + \"_Human_Chpr_CPM\"] + df[mapping[\"S1\"] + \"_Chimp_Chpr_CPM\"] + df[mapping[\"S2\"] + \"_Human_Chpr_CPM\"] + df[mapping[\"S2\"] + \"_Chimp_Chpr_CPM\"]\n",
    "    df[mapping[\"S1\"] + \"_fc_Humr\"] = df[mapping[\"S1\"] + \"_Human_Humr_CPM\"]/df[mapping[\"S1\"] + \"_Chimp_Humr_CPM\"]\n",
    "    df[mapping[\"S1\"] + \"_fc_Chpr\"] = df[mapping[\"S1\"] + \"_Human_Chpr_CPM\"]/df[mapping[\"S1\"] + \"_Chimp_Chpr_CPM\"]\n",
    "    df[mapping[\"S2\"] + \"_fc_Humr\"] = df[mapping[\"S2\"] + \"_Human_Humr_CPM\"]/df[mapping[\"S2\"] + \"_Chimp_Humr_CPM\"]\n",
    "    df[mapping[\"S2\"] + \"_fc_Chpr\"] = df[mapping[\"S2\"] + \"_Human_Chpr_CPM\"]/df[mapping[\"S2\"] + \"_Chimp_Chpr_CPM\"]\n",
    "    if ct == \"PP\":\n",
    "        df[\"l2fc_Humr\"] = np.log2(df[mapping[\"S1\"] + \"_fc_Humr\"])\n",
    "        df[\"l2fc_Chpr\"] = np.log2(df[mapping[\"S1\"] + \"_fc_Chpr\"])\n",
    "    else:\n",
    "        df[\"l2fc_Humr\"] = np.log2((df[mapping[\"S1\"] + \"_fc_Humr\"] + df[mapping[\"S2\"] + \"_fc_Humr\"])/2)\n",
    "        df[\"l2fc_Chpr\"] = np.log2((df[mapping[\"S1\"] + \"_fc_Chpr\"] + df[mapping[\"S2\"] + \"_fc_Chpr\"])/2)\n",
    "    df[\"mean_l2fc\"] = (df[\"l2fc_Humr\"] + df[\"l2fc_Chpr\"])/2\n",
    "\n",
    "    df[\"mean_counts_chimp_humr\"] = (df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix] + df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_humreffed\" + suffix])/2\n",
    "    df[\"mean_counts_human_humr\"] = (df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix] + df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_humreffed\" + suffix])/2\n",
    "    df[\"mean_counts_chimp_chpr\"] = (df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix] + df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_chpreffed\" + suffix])/2\n",
    "    df[\"mean_counts_human_chpr\"] = (df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix] + df[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_chpreffed\" + suffix])/2\n",
    "\n",
    "    out = []\n",
    "    for index, row in df.iterrows():\n",
    "        if (row[\"mean_counts_human_humr\"] > 25 and row[\"mean_counts_human_chpr\"] > 25) or (row[\"mean_counts_chimp_humr\"] > 25 and row[\"mean_counts_chimp_chpr\"] > 25):\n",
    "            if not bias_check(np.log2(row[mapping[\"S1\"] + \"_fc_Humr\"]), np.log2(row[mapping[\"S1\"] + \"_fc_Chpr\"])) and not bias_check(np.log2(row[mapping[\"S2\"] + \"_fc_Humr\"]), np.log2(row[mapping[\"S2\"] + \"_fc_Chpr\"])):\n",
    "                if match_dir(np.log2(row[mapping[\"S1\"] + \"_fc_Humr\"]), np.log2(row[mapping[\"S2\"] + \"_fc_Humr\"])) and match_dir(np.log2(row[mapping[\"S1\"] + \"_fc_Chpr\"]), np.log2(row[mapping[\"S2\"] + \"_fc_Chpr\"])):\n",
    "                    if map_bias_check(row[\"Total_Counts_Humr\"], row[\"Total_Counts_Chpr\"]):\n",
    "                        if row[0] != \"chr20\":\n",
    "                            ch = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix] + row[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_humreffed\" + suffix]\n",
    "                            hh = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix] + row[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_humreffed\" + suffix]\n",
    "                            cc = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix] + row[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Chimp_chpreffed\" + suffix]\n",
    "                            hc = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix] + row[mapping[\"S2\"] + \"_\" + ct + \"_Hyb2_Human_chpreffed\" + suffix]\n",
    "                            chimp_pval = binom_test(hc, cc + hc)\n",
    "                            human_pval = binom_test(hh, ch + hh)\n",
    "                            out.append(list(row) + [chimp_pval, human_pval])\n",
    "    df_filt_filt = pd.DataFrame(out)\n",
    "    df_filt_filt.columns = list(df.columns) + [\"Chimp binom_pval\", \"Human binom_pval\"]\n",
    "    if \"nterpeak\" in fold:\n",
    "        df_filt_filt[\"Peak Humreffed\"] = df_filt_filt[\"Peak\"]\n",
    "        df_filt_filt[\"Peak Chpreffed\"] = df_filt_filt[\"Peak\"]\n",
    "    if fold == \"All_Peaks\":\n",
    "        filee = \"All_Peaks_Peaklist_Final_Anno_Humreffed_fixeded.bed\"\n",
    "    elif fold == \"Down\":\n",
    "        filee = \"All_Peaks_Peaklist_Down_Final_Anno_Humreffed_fixeded.bed\"\n",
    "    elif fold == \"Interpeak\":\n",
    "        filee = \"All_Peaks_Peaklist_Interpeak_Final_Anno_Humreffed_fixeded_del10.txt\"\n",
    "    elif fold == \"Interpeak_Down\":\n",
    "        filee = \"All_Peaks_Peaklist_Interpeak_Down_Final_Anno_Humreffed_fixeded_del10.txt\"\n",
    "    v = pd.read_csv(filee, sep = \"\\t\", header = None).set_index(3)\n",
    "    \n",
    "    df_filt_filt_ind = df_filt_filt.set_index(\"Peak Humreffed\")\n",
    "    out = []\n",
    "    for index, row in df_filt_filt_ind.iterrows():\n",
    "        try:\n",
    "            r = v.loc[index]\n",
    "            if r[0] != \"chr20\":\n",
    "                out.append([index] + list(row) + [r[0] + \":\" + str(r[1]) + \"-\" + str(r[2])])\n",
    "        except:\n",
    "            pass\n",
    "    dff = pd.DataFrame(out)\n",
    "    dff.columns = [\"Peak Humreffed\"] + list(df_filt_filt_ind.columns) + [\"Genomic location\"]\n",
    "    dff[\"Chimp FDR\"] = fdrcorrection(dff[\"Chimp binom_pval\"])[1]\n",
    "    dff[\"Human FDR\"] = fdrcorrection(dff[\"Human binom_pval\"])[1]\n",
    "    dff[\"Max FDR\"] = np.max([dff[\"Chimp FDR\"], dff[\"Human FDR\"]], axis = 0)\n",
    "    dff = dff.sort_values(\"Max FDR\")\n",
    "    dff = pd.DataFrame(dff[[\"Peak Humreffed\", \"Peak Chpreffed\", \"l2fc_Humr\", \"l2fc_Chpr\", \"mean_l2fc\", \"Chimp binom_pval\", \"Human binom_pval\", \"Genomic location\", \"Chimp FDR\", \"Human FDR\", \"Max FDR\"]])\n",
    "    #dff.to_csv(\"\" + ct + \"_ATAC_Filtered_all_peaks_new_new.txt\", sep = \"\\t\", index = False)\n",
    "    #file = \"\" + ct + \"_ATAC_Filtered_all_peaks_new_new.txt\"\n",
    "    if \"Interpeak\" not in fold:\n",
    "        v = pd.read_csv(\"Correct_Gene_Names.txt\", sep = \"\\t\", header = None).set_index(0)\n",
    "        lll = list(v.index)\n",
    "        vv = dff\n",
    "        out = []\n",
    "        for index, row in vv.iterrows():\n",
    "            new_row = list(row)\n",
    "            #name = row[\"Peak Humreffed\"].split(\"_\")\n",
    "            #name2 = row[\"Peak Chpreffed\"].split(\"_\")\n",
    "            l = list(row)\n",
    "            name = l[0]\n",
    "            name2 = l[1]\n",
    "            for key in fix_all_peaks.keys():\n",
    "                if key in name:\n",
    "                    name = name.replace(key, fix_all_peaks[key])\n",
    "                if key in name2:\n",
    "                    name2 = name2.replace(key, fix_all_peaks[key])\n",
    "            if \"enhancer\" in name:\n",
    "                name = name.split(\"_\")\n",
    "                gene1 = name[-4]\n",
    "                gene2 = name[-2]\n",
    "                if gene1 in list(v.index):\n",
    "                    new_gene1 = v.loc[gene1][1]\n",
    "                else:\n",
    "                    new_gene1 = gene1\n",
    "                if gene2 in list(v.index):\n",
    "                    new_gene2 = v.loc[gene2][1]\n",
    "                else:\n",
    "                    new_gene2 = gene2\n",
    "                name[-4] = new_gene1\n",
    "                name[-2] = new_gene2\n",
    "                l[0] = \"_\".join(name)\n",
    "            elif \"promoter\" in name:\n",
    "                ll = name.split(\"_\")\n",
    "                for i in ll:\n",
    "                    if i in lll:\n",
    "                        name = name.replace(i, v.loc[i][1])\n",
    "                l[0] = name\n",
    "\n",
    "            if \"enhancer\" in name2:\n",
    "                name2 = name2.split(\"_\")\n",
    "                gene1 = name2[-4]\n",
    "                gene2 = name2[-2]\n",
    "                if gene1 in list(v.index):\n",
    "                    new_gene1 = v.loc[gene1][1]\n",
    "                else:\n",
    "                    new_gene1 = gene1\n",
    "                if gene2 in list(v.index):\n",
    "                    new_gene2 = v.loc[gene2][1]\n",
    "                else:\n",
    "                    new_gene2 = gene2\n",
    "                name2[-4] = new_gene1\n",
    "                name2[-2] = new_gene2\n",
    "                l[1] = \"_\".join(name2)\n",
    "            elif \"promoter\" in name2:\n",
    "                ll = name2.split(\"_\")\n",
    "                for i in ll:\n",
    "                    if i in lll:\n",
    "                        name2 = name2.replace(i, v.loc[i][1])\n",
    "                l[1] = name2\n",
    "            out.append(new_row)\n",
    "        df = pd.DataFrame(out)\n",
    "        df.columns = vv.columns\n",
    "    if \"nterpeak\" in fold:\n",
    "        df = dff\n",
    "    file = ct + \"_ATAC_Filtered_\" + fold + \"_fixed.txt\"\n",
    "    df.to_csv(file, sep = \"\\t\", index = False)\n",
    "\n",
    "    #Convert it to a bed file\n",
    "    v = pd.read_csv(file, sep = \"\\t\")\n",
    "    out = []\n",
    "    for index, row in v.iterrows():\n",
    "        g = row[\"Genomic location\"]\n",
    "        l = [g.split(\":\")[0], g.split(\":\")[1].split(\"-\")[0], g.split(\":\")[1].split(\"-\")[1]] + list(row)\n",
    "        out.append(l)\n",
    "    df = pd.DataFrame(out)\n",
    "    df.to_csv(file.replace(\"_TEST.txt\", \".bed\"), sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02585988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The analogous code when we have single replicate\n",
    "def filter_sing(ct=\"HP\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC16\"}, suffix = \"_all_peaks.txt\"):\n",
    "    df_hum = readin(ct, \"umreffed\", fold)\n",
    "    df_chp = readin(ct, \"hpreffed\", fold)\n",
    "    indices = []\n",
    "    for index, row in df_hum.iterrows():\n",
    "        if \"promoter\" in row[\"Peak\"]:\n",
    "            ad = row[\"Peak\"].split(\"promoter\")[0][:-1]\n",
    "        else:\n",
    "            ad = row[\"Peak\"].split(\"enhancer\")[0][:-1]\n",
    "        indices.append(ad)\n",
    "    df_hum.index = indices\n",
    "\n",
    "    indices = []\n",
    "    for index, row in df_chp.iterrows():\n",
    "        if \"promoter\" in row[\"Peak\"]:\n",
    "            ad = row[\"Peak\"].split(\"promoter\")[0][:-1]\n",
    "        else:\n",
    "            ad = row[\"Peak\"].split(\"enhancer\")[0][:-1]\n",
    "        indices.append(ad)\n",
    "    df_chp.index = indices\n",
    "\n",
    "    c = list(df_hum.columns)\n",
    "    c[0] = \"Peak Humreffed\"\n",
    "    df_hum.columns = c\n",
    "    c = list(df_chp.columns)\n",
    "    c[0] = \"Peak Chpreffed\"\n",
    "    df_chp.columns = c\n",
    "    df = df_hum.join(df_chp)\n",
    "    print(df)\n",
    "    df[mapping[\"S1\"] + \"_Human_Humr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix])\n",
    "    df[mapping[\"S1\"] + \"_Chimp_Humr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix])\n",
    "    df[mapping[\"S1\"] + \"_Human_Chpr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix])\n",
    "    df[mapping[\"S1\"] + \"_Chimp_Chpr_CPM\"] = 1000000*(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix]+1)/np.sum(df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix])\n",
    "\n",
    "    df[\"Total_Counts_Humr\"] = df[mapping[\"S1\"] + \"_Human_Humr_CPM\"] + df[mapping[\"S1\"] + \"_Chimp_Humr_CPM\"]\n",
    "    df[\"Total_Counts_Chpr\"] = df[mapping[\"S1\"] + \"_Human_Chpr_CPM\"] + df[mapping[\"S1\"] + \"_Chimp_Chpr_CPM\"]\n",
    "    df[mapping[\"S1\"] + \"_fc_Humr\"] = df[mapping[\"S1\"] + \"_Human_Humr_CPM\"]/df[mapping[\"S1\"] + \"_Chimp_Humr_CPM\"]\n",
    "    df[mapping[\"S1\"] + \"_fc_Chpr\"] = df[mapping[\"S1\"] + \"_Human_Chpr_CPM\"]/df[mapping[\"S1\"] + \"_Chimp_Chpr_CPM\"]\n",
    "    df[\"l2fc_Humr\"] = np.log2(df[mapping[\"S1\"] + \"_fc_Humr\"])\n",
    "    df[\"l2fc_Chpr\"] = np.log2(df[mapping[\"S1\"] + \"_fc_Chpr\"])\n",
    "    df[\"mean_l2fc\"] = (df[\"l2fc_Humr\"] + df[\"l2fc_Chpr\"])/2\n",
    "\n",
    "    df[\"mean_counts_chimp_humr\"] = df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix]\n",
    "    df[\"mean_counts_human_humr\"] = df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix]\n",
    "    df[\"mean_counts_chimp_chpr\"] = df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix]\n",
    "    df[\"mean_counts_human_chpr\"] = df[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix]\n",
    "\n",
    "    out = []\n",
    "    for index, row in df.iterrows():\n",
    "        if (row[\"mean_counts_human_humr\"] > 25 and row[\"mean_counts_human_chpr\"] > 25) or (row[\"mean_counts_chimp_humr\"] > 25 and row[\"mean_counts_chimp_chpr\"] > 25):\n",
    "            if not bias_check(np.log2(row[mapping[\"S1\"] + \"_fc_Humr\"]), np.log2(row[mapping[\"S1\"] + \"_fc_Chpr\"])):\n",
    "                if map_bias_check(row[\"Total_Counts_Humr\"], row[\"Total_Counts_Chpr\"]):\n",
    "                    if row[0] != \"chr20\":\n",
    "                        ch = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_humreffed\" + suffix]\n",
    "                        hh = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_humreffed\" + suffix]\n",
    "                        cc = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Chimp_chpreffed\" + suffix]\n",
    "                        hc = row[mapping[\"S1\"] + \"_\" + ct + \"_Hyb1_Human_chpreffed\" + suffix]\n",
    "                        chimp_pval = binom_test(hc, cc + hc)\n",
    "                        human_pval = binom_test(hh, ch + hh)\n",
    "                        out.append(list(row) + [chimp_pval, human_pval])\n",
    "    df_filt_filt = pd.DataFrame(out)\n",
    "    df_filt_filt.columns = list(df.columns) + [\"Chimp binom_pval\", \"Human binom_pval\"]\n",
    "    print(df_filt_filt)\n",
    "    v = pd.read_csv(\"All_Peaks_Peaklist_Down_Final_Anno_Humreffed_fixeded.bed\", sep = \"\\t\", header = None).set_index(3)\n",
    "    df_filt_filt_ind = df_filt_filt.set_index(\"Peak Humreffed\")\n",
    "    out = []\n",
    "    for index, row in df_filt_filt_ind.iterrows():\n",
    "        try:\n",
    "            r = v.loc[index]\n",
    "            if r[0] != \"chr20\":\n",
    "                out.append([index] + list(row) + [r[0] + \":\" + str(r[1]) + \"-\" + str(r[2])])\n",
    "        except:\n",
    "            pass\n",
    "    dff = pd.DataFrame(out)\n",
    "    dff.columns = list(df_filt_filt.columns) + [\"Genomic location\"]\n",
    "    dff[\"Chimp FDR\"] = fdrcorrection(dff[\"Chimp binom_pval\"])[1]\n",
    "    dff[\"Human FDR\"] = fdrcorrection(dff[\"Human binom_pval\"])[1]\n",
    "    dff[\"Max FDR\"] = np.max([dff[\"Chimp FDR\"], dff[\"Human FDR\"]], axis = 0)                                           \n",
    "    dff = dff.sort_values(\"Max FDR\")\n",
    "    dff = pd.DataFrame(dff[[\"Peak Humreffed\", \"Peak Chpreffed\", \"l2fc_Humr\", \"l2fc_Chpr\", \"mean_l2fc\", \"Chimp binom_pval\", \"Human binom_pval\", \"Genomic location\", \"Chimp FDR\", \"Human FDR\", \"Max FDR\"]])\n",
    "    #dff.to_csv(\"\" + ct + \"_ATAC_Filtered_all_peaks_new_new.txt\", sep = \"\\t\", index = False)\n",
    "\n",
    "    #file = \"\" + ct + \"_ATAC_Filtered_all_peaks_new_new.txt\"\n",
    "    v = pd.read_csv(\"Correct_Gene_Names.txt\", sep = \"\\t\", header = None).set_index(0)\n",
    "    lll = list(v.index)\n",
    "    vv = dff\n",
    "    out = []\n",
    "    for index, row in vv.iterrows():\n",
    "        new_row = list(row)\n",
    "        #name = row[\"Peak Humreffed\"].split(\"_\")\n",
    "        #name2 = row[\"Peak Chpreffed\"].split(\"_\")\n",
    "        l = list(row)\n",
    "        name = l[0]\n",
    "        name2 = l[1]\n",
    "        for key in fix_all_peaks.keys():\n",
    "            if key in name:\n",
    "                name = name.replace(key, fix_all_peaks[key])\n",
    "            if key in name2:\n",
    "                name2 = name2.replace(key, fix_all_peaks[key])\n",
    "        if \"enhancer\" in name:\n",
    "            name = name.split(\"_\")\n",
    "            gene1 = name[-4]\n",
    "            gene2 = name[-2]\n",
    "            if gene1 in list(v.index):\n",
    "                new_gene1 = v.loc[gene1][1]\n",
    "            else:\n",
    "                new_gene1 = gene1\n",
    "            if gene2 in list(v.index):\n",
    "                new_gene2 = v.loc[gene2][1]\n",
    "            else:\n",
    "                new_gene2 = gene2\n",
    "            name[-4] = new_gene1\n",
    "            name[-2] = new_gene2\n",
    "            l[0] = \"_\".join(name)\n",
    "        elif \"promoter\" in name:\n",
    "            ll = name.split(\"_\")\n",
    "            for i in ll:\n",
    "                if i in lll:\n",
    "                    name = name.replace(i, v.loc[i][1])\n",
    "            l[0] = name\n",
    "\n",
    "        if \"enhancer\" in name2:\n",
    "            name2 = name2.split(\"_\")\n",
    "            gene1 = name2[-4]\n",
    "            gene2 = name2[-2]\n",
    "            if gene1 in list(v.index):\n",
    "                new_gene1 = v.loc[gene1][1]\n",
    "            else:\n",
    "                new_gene1 = gene1\n",
    "            if gene2 in list(v.index):\n",
    "                new_gene2 = v.loc[gene2][1]\n",
    "            else:\n",
    "                new_gene2 = gene2\n",
    "            name2[-4] = new_gene1\n",
    "            name2[-2] = new_gene2\n",
    "            l[1] = \"_\".join(name2)\n",
    "        elif \"promoter\" in name2:\n",
    "            ll = name2.split(\"_\")\n",
    "            for i in ll:\n",
    "                if i in lll:\n",
    "                    name2 = name2.replace(i, v.loc[i][1])\n",
    "            l[1] = name2\n",
    "        out.append(new_row)\n",
    "    df = pd.DataFrame(out)\n",
    "    df.columns = vv.columns\n",
    "    file = ct + \"_ATAC_Filtered_\" + fold + \"_fixed.txt\"\n",
    "    df.to_csv(file, sep = \"\\t\", index = False)\n",
    "\n",
    "    #Convert it to a bed file\n",
    "    v = pd.read_csv(file, sep = \"\\t\")\n",
    "    out = []\n",
    "    for index, row in v.iterrows():\n",
    "        g = row[\"Genomic location\"]\n",
    "        l = [g.split(\":\")[0], g.split(\":\")[1].split(\"-\")[0], g.split(\":\")[1].split(\"-\")[1]] + list(row)\n",
    "        out.append(l)\n",
    "    df = pd.DataFrame(out)\n",
    "    df.to_csv(file.replace(\".txt\", \".bed\"), sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rep(ct=\"CM\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC7\", \"S2\":\"ATAC8\"}, suffix = \"_all_peaks.txt\")\n",
    "filter_rep(ct=\"MN\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC35\", \"S2\":\"ATAC36\"}, suffix = \"_all_peaks.txt\")\n",
    "filter_rep(ct=\"PP\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC19\", \"S2\":\"ATAC20\"}, suffix = \"_all_peaks.txt\")\n",
    "filter_sing(ct=\"SKM\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC11\"}, suffix = \"_all_peaks.txt\")\n",
    "filter_sing(ct=\"HP\", fold=\"All_Peaks\", mapping={\"S1\":\"ATAC16\"}, suffix = \"_all_peaks.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
